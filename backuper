#!/bin/bash

# Get script running directory
running_dir="$( cd "$( dirname "${BASH_SOURCE[0]}" )" && pwd )"

echo "`date`: backup script started from $running_dir "$'\r'

# Import variables from backuper.config
source $running_dir/backuper.config

# Change directory to backups folder
cd /home/backups/$name

# Remove old backups leftovers (just in case)
rm backup.sqsh
rm "$name.backup.$(date +"%Y-%m-%d").sqsh.gpg"

# Remove all but newest backups (to make room)
ls -1tr | head -n -1 | xargs -d '\n' rm -f --

# Create SquashFS from / without progress bar, using xz compression, excluding folders requiring backups and the backups folder
sudo mksquashfs / backup.sqsh -no-progress -comp xz -e media dev run mnt proc sys tmp $excluded

# encrypt created SquashFS with GPG for $gpg_recipient
sudo gpg2 --output "$name.backup.$(date +"%Y-%m-%d").sqsh.gpg" --encrypt --recipient $gpg_recipient backup.sqsh

# Report success or failure
if [[ $? > 0 ]]
then
        echo "`date`: ERROR: gpg2 encryption failure"$'\r'
else
        echo "`date`: gpg2 encryption successful"$'\r'
fi

# Remove Unencrypted SquashFS
rm backup.sqsh

# change permissions for backups user
chown backups:backups "$name.backup.$(date +"%Y-%m-%d").sqsh.gpg"

# Send encrypted SquashFS to $name over rsync
# Encapsulated in a while loop to keep trying until transfer is complete
while [ 1 ]
do
        # Ruun rsync as user backups for ssh keys
        sudo -u backups rsync -avz "$name.backup.$(date +"%Y-%m-%d").sqsh.gpg" $backup_destination --partial --human-readable --append-verify
        if [[ $? > 0 ]]
        # if rsync failed: report, wait and try again
        then
                echo "`date`: ERROR: rsync transfer failure, waiting 60s then trying again..."$'\r'
                sleep 60
        # else report success and exit loop
        else
                echo "`date`: rsync transfer successful"$'\r'
                break
        fi
done
